{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(df):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for x in df['f1']:\n",
    "        if x!=-1:\n",
    "            sum+=x\n",
    "            count+=1\n",
    "    avg = sum/count\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timer function\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model, X_train, X_valid,y_train, y_valid):\n",
    "    soft_probs = model.predict_proba(X_valid)\n",
    "    valid_auc = roc_auc_score(y_valid, soft_probs[:,1])\n",
    "    print(valid_auc)\n",
    "    train_preds = model.predict(X_train)\n",
    "    acc = accuracy_score(y_train, train_preds)\n",
    "    print(acc)\n",
    "    preds = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    print(acc)\n",
    "    print(classification_report(y_valid,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.638300e+04</td>\n",
       "      <td>16383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>0.942135</td>\n",
       "      <td>43007.775865</td>\n",
       "      <td>1.044375</td>\n",
       "      <td>11.770938</td>\n",
       "      <td>118323.581456</td>\n",
       "      <td>1.044436</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>117089.674113</td>\n",
       "      <td>169730.178600</td>\n",
       "      <td>...</td>\n",
       "      <td>25894.316914</td>\n",
       "      <td>119045.099005</td>\n",
       "      <td>184622.040835</td>\n",
       "      <td>1.047305</td>\n",
       "      <td>125959.667765</td>\n",
       "      <td>1.044558</td>\n",
       "      <td>1.045718</td>\n",
       "      <td>1.041934</td>\n",
       "      <td>3.271890e+04</td>\n",
       "      <td>1.043948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4729.509065</td>\n",
       "      <td>0.233495</td>\n",
       "      <td>33611.182771</td>\n",
       "      <td>0.264806</td>\n",
       "      <td>353.187115</td>\n",
       "      <td>4518.059755</td>\n",
       "      <td>0.265601</td>\n",
       "      <td>0.293892</td>\n",
       "      <td>10261.292970</td>\n",
       "      <td>69396.677853</td>\n",
       "      <td>...</td>\n",
       "      <td>36086.993946</td>\n",
       "      <td>18321.987129</td>\n",
       "      <td>100590.811845</td>\n",
       "      <td>0.306239</td>\n",
       "      <td>31091.344158</td>\n",
       "      <td>0.262576</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.246597</td>\n",
       "      <td>3.184929e+06</td>\n",
       "      <td>0.259640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>23779.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4292.000000</td>\n",
       "      <td>4673.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4674.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4096.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20311.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118096.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>117906.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4554.000000</td>\n",
       "      <td>118395.000000</td>\n",
       "      <td>118398.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118274.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35527.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>128130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13234.000000</td>\n",
       "      <td>118929.000000</td>\n",
       "      <td>119095.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118568.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12287.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74240.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>118386.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>234498.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>38902.000000</td>\n",
       "      <td>120539.000000</td>\n",
       "      <td>290919.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>312152.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>43910.160000</td>\n",
       "      <td>286791.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>311178.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>311696.000000</td>\n",
       "      <td>286792.000000</td>\n",
       "      <td>308574.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.042886e+08</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id             Y             f1            f2            f3  \\\n",
       "count  16383.000000  16383.000000   16383.000000  16383.000000  16383.000000   \n",
       "mean    8192.000000      0.942135   43007.775865      1.044375     11.770938   \n",
       "std     4729.509065      0.233495   33611.182771      0.264806    353.187115   \n",
       "min        1.000000      0.000000      -1.000000      1.000000      1.770000   \n",
       "25%     4096.500000      1.000000   20311.000000      1.000000      1.770000   \n",
       "50%     8192.000000      1.000000   35527.000000      1.000000      1.770000   \n",
       "75%    12287.500000      1.000000   74240.500000      1.000000      3.540000   \n",
       "max    16383.000000      1.000000  312152.000000      7.000000  43910.160000   \n",
       "\n",
       "                  f4            f5            f6             f7  \\\n",
       "count   16383.000000  16383.000000  16383.000000   16383.000000   \n",
       "mean   118323.581456      1.044436      0.050052  117089.674113   \n",
       "std      4518.059755      0.265601      0.293892   10261.292970   \n",
       "min     23779.000000      1.000000      0.000000    4292.000000   \n",
       "25%    118096.000000      1.000000      0.000000  117961.000000   \n",
       "50%    118300.000000      1.000000      0.000000  117961.000000   \n",
       "75%    118386.000000      1.000000      0.000000  117961.000000   \n",
       "max    286791.000000      9.000000     10.000000  311178.000000   \n",
       "\n",
       "                  f8  ...            f15            f16            f17  \\\n",
       "count   16383.000000  ...   16383.000000   16383.000000   16383.000000   \n",
       "mean   169730.178600  ...   25894.316914  119045.099005  184622.040835   \n",
       "std     69396.677853  ...   36086.993946   18321.987129  100590.811845   \n",
       "min      4673.000000  ...      25.000000    4674.000000    3130.000000   \n",
       "25%    117906.000000  ...    4554.000000  118395.000000  118398.000000   \n",
       "50%    128130.000000  ...   13234.000000  118929.000000  119095.000000   \n",
       "75%    234498.500000  ...   38902.000000  120539.000000  290919.000000   \n",
       "max    311867.000000  ...  311696.000000  286792.000000  308574.000000   \n",
       "\n",
       "                f18            f19           f20           f21           f22  \\\n",
       "count  16383.000000   16383.000000  16383.000000  16383.000000  16383.000000   \n",
       "mean       1.047305  125959.667765      1.044558      1.045718      1.041934   \n",
       "std        0.306239   31091.344158      0.262576      0.266874      0.246597   \n",
       "min        1.000000  117879.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000  118274.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000  118568.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000  120006.000000      1.000000      1.000000      1.000000   \n",
       "max       18.000000  311867.000000      8.000000      8.000000      7.000000   \n",
       "\n",
       "                f23           f24  \n",
       "count  1.638300e+04  16383.000000  \n",
       "mean   3.271890e+04      1.043948  \n",
       "std    3.184929e+06      0.259640  \n",
       "min    1.000000e+00      1.000000  \n",
       "25%    1.000000e+00      1.000000  \n",
       "50%    2.000000e+00      1.000000  \n",
       "75%    9.000000e+00      1.000000  \n",
       "max    4.042886e+08      8.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_final.csv\")\n",
    "df.describe()\n",
    "# f1_avg = average(df)\n",
    "# df['f1'].replace(-1,f1_avg, inplace = True)\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,'Y']\n",
    "X = df.loc[:,'f1':'f24']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size = 0.75, test_size = 0.25,random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,)\n",
    "                     (colsample_bytree=0.4,subsample = 1,max_depth=7,\n",
    "                            n_estimators=1350, learning_rate =0.012,\n",
    "                            colsample_bylevel=0.6,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42)\n",
    " (colsample_bytree=0.395,subsample = 0.8667,max_depth=10,\n",
    "                            n_estimators=1550, learning_rate =0.0108,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42) \n",
    " (colsample_bytree=0.395,subsample = 0.8667,max_depth=11,\n",
    "                            n_estimators=1538, learning_rate =0.0105,colsample_bynode = 0.87,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42, max_delta_step =1.168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'colsample_bylevel': 0.8789900701708724,\n",
    " 'colsample_bynode': 0.9962857441883629,\n",
    " 'colsample_bytree': 0.7448296344616587,\n",
    " 'learning_rate': 0.036130784427853585,\n",
    " 'max_delta_step': 4.953440861348021,\n",
    " 'max_depth': 9,\n",
    " 'n_estimators': 980,\n",
    " 'subsample': 0.6002618478477451}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660956408648169\n",
      "1.0\n",
      "0.9609375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.31      0.47       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.94      0.66      0.72      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_trial = XGBClassifier  (\n",
    "                           n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42,\n",
    "                            **params\n",
    "                             )\n",
    "model_trial.fit(X_train, y_train)\n",
    "results(model_trial,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the auc score is slighly less, the precision and recal is slightly better than the current best model. Lets make a submission to see if its worth relying on precision/recall. Yes, I think it is reliable as it did not break it. \n",
    "Update: Making a new submission after adding new parameter max_delta_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.475, booster='gbtree', colsample_bylevel=0.65,\n",
       "              colsample_bynode=0.87, colsample_bytree=0.395, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.0105, max_delta_step=1.168, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1538, n_jobs=-1, num_parallel_tree=1,\n",
       "              random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.8667, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trial.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"test_final.csv\")\n",
    "testdf['f1'].replace(-1,f1_avg, inplace = True)\n",
    "X_test = testdf.loc[:,'f1':'f24']\n",
    "test_preds = model_trial.predict_proba(X_test)\n",
    "sub10 = {\"Id\":testdf['Id'],\"Y\":test_preds[:,1]}\n",
    "sub10= pd.DataFrame(data=sub10)\n",
    "sub10.to_csv(\"submissions/sub10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Slight improvement noticed in LB. Score now is 0.90633 Stack with lightgbm now\n",
    " EDIT: Sub8 overwrote sub6 but its ok. Dont commit changes to sub6. And score increased. Updating current best xgb params.\n",
    " EDIT: Testing sub9 with greater reliance on the randomized cross validation results instead of single validation score. This test gave worse results on Leaderboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thorough Randomized search with our current best XGBoost\n",
    "Goal to achieve validation auc of 0.9 before next submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "             'min_child_weight':[1e-2, 1e-1, 1,],\n",
    "             'max_delta_step':sp_uniform(loc=0.5,scale=1.5)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trial = XGBClassifier(colsample_bytree=0.395,subsample = 0.8667,max_depth=11,\n",
    "                            n_estimators=1538, learning_rate =0.0105,colsample_bynode = 0.87,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42, max_delta_step =1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 10 minutes and 38.99 seconds.\n",
      "0.883110541801948\n",
      "0.9985350370310084\n",
      "0.960205078125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.29      0.44       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.96      0.64      0.71      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n",
      "{'max_delta_step': 0.7751521847992457, 'min_child_weight': 0.01}\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 20 #number of random parameter combos to pick\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 43)\n",
    "random_search = RandomizedSearchCV(model_trial, param_distributions=params,\n",
    "                                   n_iter=param_comb, scoring='roc_auc', \n",
    "                                   n_jobs=-1, cv=skf.split(X_train,y_train), \n",
    "                                   verbose=3, random_state=42 )\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "tuned = random_search.fit(X_train, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable\n",
    "results(tuned,X_train, X_valid, y_train, y_valid)\n",
    "print(tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMClassifier Ahead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_lgb=LGBMClassifier(colsample_bytree=0.9,subsample =0.5,max_depth=-1,\n",
    "                            n_estimators=5000, learning_rate =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 3 minutes and 16.93 seconds.\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 25 #number of random parameter combos to pick\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 43)\n",
    "random_search = RandomizedSearchCV(model_lgb, param_distributions=params,\n",
    "                                   n_iter=param_comb, scoring='roc_auc', \n",
    "                                   n_jobs=-1, cv=skf.split(X_train,y_train), \n",
    "                                   verbose=3, random_state=42 )\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "tuned = random_search.fit(X_train, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8597658555932703\n",
      "0.9858386912997477\n",
      "0.96044921875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.32      0.47       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.92      0.66      0.72      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results(tuned,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6640914962437607,\n",
       " 'min_child_samples': 363,\n",
       " 'min_child_weight': 0.01,\n",
       " 'num_leaves': 19,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 5,\n",
       " 'subsample': 0.3457888702304499}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.331, subsample=0.5 will be ignored. Current value: bagging_fraction=0.331\n",
      "0.8509583456316412\n",
      "0.9598762920159518\n",
      "0.9619140625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.47       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.98      0.65      0.72      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb=LGBMClassifier(colsample_bytree=0.9,subsample =0.3,max_depth=-1,\n",
    "                            n_estimators=1850, learning_rate =0.01)\n",
    "model_lgb.fit(X_train,y_train)\n",
    "results(model_lgb,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
