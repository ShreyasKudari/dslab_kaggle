{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(df):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for x in df['f1']:\n",
    "        if x!=-1:\n",
    "            sum+=x\n",
    "            count+=1\n",
    "    avg = sum/count\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model, X_train, X_valid,y_train, y_valid):\n",
    "    soft_probs = model.predict_proba(X_valid)\n",
    "    valid_auc = roc_auc_score(y_valid, soft_probs[:,1])\n",
    "    print(valid_auc)\n",
    "    train_preds = model.predict(X_train)\n",
    "    acc = accuracy_score(y_train, train_preds)\n",
    "    print(acc)\n",
    "    preds = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    print(acc)\n",
    "    print(classification_report(y_valid,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timer function\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.638300e+04</td>\n",
       "      <td>16383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>0.942135</td>\n",
       "      <td>43031.415720</td>\n",
       "      <td>1.044375</td>\n",
       "      <td>11.770938</td>\n",
       "      <td>118323.581456</td>\n",
       "      <td>1.044436</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>117089.674113</td>\n",
       "      <td>169730.178600</td>\n",
       "      <td>...</td>\n",
       "      <td>25894.316914</td>\n",
       "      <td>119045.099005</td>\n",
       "      <td>184622.040835</td>\n",
       "      <td>1.047305</td>\n",
       "      <td>125959.667765</td>\n",
       "      <td>1.044558</td>\n",
       "      <td>1.045718</td>\n",
       "      <td>1.041934</td>\n",
       "      <td>3.271890e+04</td>\n",
       "      <td>1.043948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4729.509065</td>\n",
       "      <td>0.233495</td>\n",
       "      <td>33596.053696</td>\n",
       "      <td>0.264806</td>\n",
       "      <td>353.187115</td>\n",
       "      <td>4518.059755</td>\n",
       "      <td>0.265601</td>\n",
       "      <td>0.293892</td>\n",
       "      <td>10261.292970</td>\n",
       "      <td>69396.677853</td>\n",
       "      <td>...</td>\n",
       "      <td>36086.993946</td>\n",
       "      <td>18321.987129</td>\n",
       "      <td>100590.811845</td>\n",
       "      <td>0.306239</td>\n",
       "      <td>31091.344158</td>\n",
       "      <td>0.262576</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.246597</td>\n",
       "      <td>3.184929e+06</td>\n",
       "      <td>0.259640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>23779.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4292.000000</td>\n",
       "      <td>4673.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4674.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4096.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20331.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118096.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>117906.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4554.000000</td>\n",
       "      <td>118395.000000</td>\n",
       "      <td>118398.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118274.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35530.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>128130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13234.000000</td>\n",
       "      <td>118929.000000</td>\n",
       "      <td>119095.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118568.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12287.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74240.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>118386.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>234498.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>38902.000000</td>\n",
       "      <td>120539.000000</td>\n",
       "      <td>290919.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>312152.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>43910.160000</td>\n",
       "      <td>286791.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>311178.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>311696.000000</td>\n",
       "      <td>286792.000000</td>\n",
       "      <td>308574.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.042886e+08</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id             Y             f1            f2            f3  \\\n",
       "count  16383.000000  16383.000000   16383.000000  16383.000000  16383.000000   \n",
       "mean    8192.000000      0.942135   43031.415720      1.044375     11.770938   \n",
       "std     4729.509065      0.233495   33596.053696      0.264806    353.187115   \n",
       "min        1.000000      0.000000      37.000000      1.000000      1.770000   \n",
       "25%     4096.500000      1.000000   20331.000000      1.000000      1.770000   \n",
       "50%     8192.000000      1.000000   35530.000000      1.000000      1.770000   \n",
       "75%    12287.500000      1.000000   74240.500000      1.000000      3.540000   \n",
       "max    16383.000000      1.000000  312152.000000      7.000000  43910.160000   \n",
       "\n",
       "                  f4            f5            f6             f7  \\\n",
       "count   16383.000000  16383.000000  16383.000000   16383.000000   \n",
       "mean   118323.581456      1.044436      0.050052  117089.674113   \n",
       "std      4518.059755      0.265601      0.293892   10261.292970   \n",
       "min     23779.000000      1.000000      0.000000    4292.000000   \n",
       "25%    118096.000000      1.000000      0.000000  117961.000000   \n",
       "50%    118300.000000      1.000000      0.000000  117961.000000   \n",
       "75%    118386.000000      1.000000      0.000000  117961.000000   \n",
       "max    286791.000000      9.000000     10.000000  311178.000000   \n",
       "\n",
       "                  f8  ...            f15            f16            f17  \\\n",
       "count   16383.000000  ...   16383.000000   16383.000000   16383.000000   \n",
       "mean   169730.178600  ...   25894.316914  119045.099005  184622.040835   \n",
       "std     69396.677853  ...   36086.993946   18321.987129  100590.811845   \n",
       "min      4673.000000  ...      25.000000    4674.000000    3130.000000   \n",
       "25%    117906.000000  ...    4554.000000  118395.000000  118398.000000   \n",
       "50%    128130.000000  ...   13234.000000  118929.000000  119095.000000   \n",
       "75%    234498.500000  ...   38902.000000  120539.000000  290919.000000   \n",
       "max    311867.000000  ...  311696.000000  286792.000000  308574.000000   \n",
       "\n",
       "                f18            f19           f20           f21           f22  \\\n",
       "count  16383.000000   16383.000000  16383.000000  16383.000000  16383.000000   \n",
       "mean       1.047305  125959.667765      1.044558      1.045718      1.041934   \n",
       "std        0.306239   31091.344158      0.262576      0.266874      0.246597   \n",
       "min        1.000000  117879.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000  118274.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000  118568.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000  120006.000000      1.000000      1.000000      1.000000   \n",
       "max       18.000000  311867.000000      8.000000      8.000000      7.000000   \n",
       "\n",
       "                f23           f24  \n",
       "count  1.638300e+04  16383.000000  \n",
       "mean   3.271890e+04      1.043948  \n",
       "std    3.184929e+06      0.259640  \n",
       "min    1.000000e+00      1.000000  \n",
       "25%    1.000000e+00      1.000000  \n",
       "50%    2.000000e+00      1.000000  \n",
       "75%    9.000000e+00      1.000000  \n",
       "max    4.042886e+08      8.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_final.csv\")\n",
    "df.describe()\n",
    "f1_avg = average(df)\n",
    "df['f1'].replace(-1,f1_avg, inplace = True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,'Y']\n",
    "X = df.loc[:,'f1':'f24']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size = 0.75, test_size = 0.25,random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best submitted params:\n",
    "(colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,)\n",
    "  (colsample_bytree=0.4,subsample = 1,max_depth=7,\n",
    "                            n_estimators=1350, learning_rate =0.012,\n",
    "                            colsample_bylevel=0.6,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42,k_neighbors=40)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8468272671930342\n",
      "0.9844763469687797\n",
      "0.948486328125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.37      0.44       224\n",
      "           1       0.96      0.98      0.97      3872\n",
      "\n",
      "    accuracy                           0.95      4096\n",
      "   macro avg       0.75      0.67      0.71      4096\n",
      "weighted avg       0.94      0.95      0.94      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_trial = XGBClassifier (colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=155, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,)  \n",
    "model_trial.fit(X_train_smote,y_train_smote)\n",
    "results(model_trial,X_train_smote, X_valid, y_train_smote, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try Near Miss undersampling\n",
    "from imblearn.under_sampling import NearMiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545124797077922\n",
      "0.9903314917127072\n",
      "0.2666015625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.93      0.12       224\n",
      "           1       0.98      0.23      0.37      3872\n",
      "\n",
      "    accuracy                           0.27      4096\n",
      "   macro avg       0.52      0.58      0.25      4096\n",
      "weighted avg       0.93      0.27      0.36      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nearmiss = XGBClassifier (colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,) \n",
    "nm = NearMiss()\n",
    "X_train_res,y_train_res = nm.fit_resample(X_train,y_train)\n",
    "model_nearmiss.fit(X_train_res,y_train_res)\n",
    "results(model_nearmiss,X_train_res, X_valid, y_train_res, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall for minority class is highest here. Maybe try combining this with XGBoost preds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835976700855963\n"
     ]
    }
   ],
   "source": [
    "model_trial = XGBClassifier (colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.65,\n",
    "                            random_state=42,)\n",
    "model_trial.fit(X_train,y_train)\n",
    "preds1 = model_nearmiss.predict_proba(X_valid)\n",
    "preds2 = model_trial.predict_proba(X_valid)\n",
    "a=0.03\n",
    "b=0.96\n",
    "preds = a*preds1+b*preds2\n",
    "valid_auc = roc_auc_score(y_valid, preds[:,1])\n",
    "print(valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771387525826446\n",
      "0.9868967201106861\n",
      "0.96044921875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.33      0.47       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.92      0.66      0.73      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Just testing stacking two similar best models...not an improvement.\n",
    "\n",
    "model_trial = XGBClassifier (colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,) \n",
    "model_trail_other = XGBClassifier (colsample_bytree=0.4,subsample = 1,max_depth=7,\n",
    "                            n_estimators=1350, learning_rate =0.012,\n",
    "                            colsample_bylevel=0.6,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42)  \n",
    "estimators = [\n",
    "     ('simple_xgb',model_trial ),\n",
    "     ('nearmiss',model_nearmiss ),\n",
    " ]\n",
    "stacked = StackingClassifier(estimators = estimators,\n",
    "                              cv=5, n_jobs=-1)\n",
    "stacked.fit(X_train, y_train)\n",
    "results(stacked,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try RUSBoostCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8191099560950413\n",
      "0.7622690648653048\n",
      "0.752197265625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.69      0.23       224\n",
      "           1       0.98      0.76      0.85      3872\n",
      "\n",
      "    accuracy                           0.75      4096\n",
      "   macro avg       0.56      0.72      0.54      4096\n",
      "weighted avg       0.93      0.75      0.82      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_estimator = AdaBoostClassifier(n_estimators = 10)\n",
    "model_ada = RUSBoostClassifier(base_estimator=base_estimator,n_estimators = 50,learning_rate=1,\n",
    "                               replacement=False,random_state=42)\n",
    "model_ada.fit(X_train, y_train)\n",
    "results(model_ada,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
