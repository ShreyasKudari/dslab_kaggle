{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targetting imbalance problem with Imbalance-XGBoost \n",
    "Until now, most of my efforts at countering the imbalance of the data has been in vain. Ultimately, I have not been able to find a solution that optimizes the accuracy and recall of the minority(0 in this case) class. Efforts with balanced bagging and SMOTE must continue as they are promising. However, I think its worth to test this new class. \n",
    "https://github.com/jhwjhw0123/Imbalance-XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best solution run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(df):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for x in df['f1']:\n",
    "        if x!=-1:\n",
    "            sum+=x\n",
    "            count+=1\n",
    "    avg = sum/count\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model, X_train, X_valid,y_train, y_valid):\n",
    "    soft_probs = model.predict_proba(X_valid)\n",
    "    valid_auc = roc_auc_score(y_valid, soft_probs[:,1])\n",
    "    print(valid_auc)\n",
    "    train_preds = model.predict(X_train)\n",
    "    acc = accuracy_score(y_train, train_preds)\n",
    "    print(acc)\n",
    "    preds = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    print(acc)\n",
    "    print(classification_report(y_valid,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.638300e+04</td>\n",
       "      <td>16383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>0.942135</td>\n",
       "      <td>43031.415720</td>\n",
       "      <td>1.044375</td>\n",
       "      <td>11.770938</td>\n",
       "      <td>118323.581456</td>\n",
       "      <td>1.044436</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>117089.674113</td>\n",
       "      <td>169730.178600</td>\n",
       "      <td>...</td>\n",
       "      <td>25894.316914</td>\n",
       "      <td>119045.099005</td>\n",
       "      <td>184622.040835</td>\n",
       "      <td>1.047305</td>\n",
       "      <td>125959.667765</td>\n",
       "      <td>1.044558</td>\n",
       "      <td>1.045718</td>\n",
       "      <td>1.041934</td>\n",
       "      <td>3.271890e+04</td>\n",
       "      <td>1.043948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4729.509065</td>\n",
       "      <td>0.233495</td>\n",
       "      <td>33596.053696</td>\n",
       "      <td>0.264806</td>\n",
       "      <td>353.187115</td>\n",
       "      <td>4518.059755</td>\n",
       "      <td>0.265601</td>\n",
       "      <td>0.293892</td>\n",
       "      <td>10261.292970</td>\n",
       "      <td>69396.677853</td>\n",
       "      <td>...</td>\n",
       "      <td>36086.993946</td>\n",
       "      <td>18321.987129</td>\n",
       "      <td>100590.811845</td>\n",
       "      <td>0.306239</td>\n",
       "      <td>31091.344158</td>\n",
       "      <td>0.262576</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.246597</td>\n",
       "      <td>3.184929e+06</td>\n",
       "      <td>0.259640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>23779.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4292.000000</td>\n",
       "      <td>4673.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4674.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4096.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20331.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118096.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>117906.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4554.000000</td>\n",
       "      <td>118395.000000</td>\n",
       "      <td>118398.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118274.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35530.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>118300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>128130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13234.000000</td>\n",
       "      <td>118929.000000</td>\n",
       "      <td>119095.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118568.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12287.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74240.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>118386.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>234498.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>38902.000000</td>\n",
       "      <td>120539.000000</td>\n",
       "      <td>290919.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16383.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>312152.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>43910.160000</td>\n",
       "      <td>286791.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>311178.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>311696.000000</td>\n",
       "      <td>286792.000000</td>\n",
       "      <td>308574.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.042886e+08</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id             Y             f1            f2            f3  \\\n",
       "count  16383.000000  16383.000000   16383.000000  16383.000000  16383.000000   \n",
       "mean    8192.000000      0.942135   43031.415720      1.044375     11.770938   \n",
       "std     4729.509065      0.233495   33596.053696      0.264806    353.187115   \n",
       "min        1.000000      0.000000      37.000000      1.000000      1.770000   \n",
       "25%     4096.500000      1.000000   20331.000000      1.000000      1.770000   \n",
       "50%     8192.000000      1.000000   35530.000000      1.000000      1.770000   \n",
       "75%    12287.500000      1.000000   74240.500000      1.000000      3.540000   \n",
       "max    16383.000000      1.000000  312152.000000      7.000000  43910.160000   \n",
       "\n",
       "                  f4            f5            f6             f7  \\\n",
       "count   16383.000000  16383.000000  16383.000000   16383.000000   \n",
       "mean   118323.581456      1.044436      0.050052  117089.674113   \n",
       "std      4518.059755      0.265601      0.293892   10261.292970   \n",
       "min     23779.000000      1.000000      0.000000    4292.000000   \n",
       "25%    118096.000000      1.000000      0.000000  117961.000000   \n",
       "50%    118300.000000      1.000000      0.000000  117961.000000   \n",
       "75%    118386.000000      1.000000      0.000000  117961.000000   \n",
       "max    286791.000000      9.000000     10.000000  311178.000000   \n",
       "\n",
       "                  f8  ...            f15            f16            f17  \\\n",
       "count   16383.000000  ...   16383.000000   16383.000000   16383.000000   \n",
       "mean   169730.178600  ...   25894.316914  119045.099005  184622.040835   \n",
       "std     69396.677853  ...   36086.993946   18321.987129  100590.811845   \n",
       "min      4673.000000  ...      25.000000    4674.000000    3130.000000   \n",
       "25%    117906.000000  ...    4554.000000  118395.000000  118398.000000   \n",
       "50%    128130.000000  ...   13234.000000  118929.000000  119095.000000   \n",
       "75%    234498.500000  ...   38902.000000  120539.000000  290919.000000   \n",
       "max    311867.000000  ...  311696.000000  286792.000000  308574.000000   \n",
       "\n",
       "                f18            f19           f20           f21           f22  \\\n",
       "count  16383.000000   16383.000000  16383.000000  16383.000000  16383.000000   \n",
       "mean       1.047305  125959.667765      1.044558      1.045718      1.041934   \n",
       "std        0.306239   31091.344158      0.262576      0.266874      0.246597   \n",
       "min        1.000000  117879.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000  118274.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000  118568.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000  120006.000000      1.000000      1.000000      1.000000   \n",
       "max       18.000000  311867.000000      8.000000      8.000000      7.000000   \n",
       "\n",
       "                f23           f24  \n",
       "count  1.638300e+04  16383.000000  \n",
       "mean   3.271890e+04      1.043948  \n",
       "std    3.184929e+06      0.259640  \n",
       "min    1.000000e+00      1.000000  \n",
       "25%    1.000000e+00      1.000000  \n",
       "50%    2.000000e+00      1.000000  \n",
       "75%    9.000000e+00      1.000000  \n",
       "max    4.042886e+08      8.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_final.csv\")\n",
    "df.describe()\n",
    "f1_avg = average(df)\n",
    "df['f1'].replace(-1,f1_avg, inplace = True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,'Y']\n",
    "X = df.loc[:,'f1':'f24']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size = 0.75, test_size = 0.25,random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best submitted params:\n",
    "(colsample_bytree=0.3,subsample = 0.7,max_depth=8,\n",
    "                            n_estimators=1550, learning_rate =0.011,\n",
    "                            colsample_bylevel=0.5,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42,)\n",
    "  (colsample_bytree=0.4,subsample = 1,max_depth=7,\n",
    "                            n_estimators=1350, learning_rate =0.012,\n",
    "                            colsample_bylevel=0.6,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42)    \n",
    "  (colsample_bytree=0.395,subsample = 0.8667,max_depth=10,\n",
    "                            n_estimators=1550, learning_rate =0.0108,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8821691447756789\n",
      "0.9894197118906161\n",
      "0.96142578125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.31      0.47       224\n",
      "           1       0.96      1.00      0.98      3872\n",
      "\n",
      "    accuracy                           0.96      4096\n",
      "   macro avg       0.95      0.66      0.72      4096\n",
      "weighted avg       0.96      0.96      0.95      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_trial = XGBClassifier(colsample_bytree=0.4,subsample = 0.8667,max_depth=8,\n",
    "                            n_estimators=1650, learning_rate =0.0119,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.55,\n",
    "                            random_state=42)\n",
    "                            \n",
    "model_trial.fit(X_train, y_train)\n",
    "results(model_trial,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Bagging \n",
    "Improves recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagging = XGBClassifier(colsample_bytree=0.395,subsample = 0.8667,max_depth=11,\n",
    "                            n_estimators=1538, learning_rate =0.0108,colsample_bynode = 0.87,\n",
    "                            colsample_bylevel=0.65,n_jobs=-1,base_score = 0.475,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8636617288961038\n",
      "0.8943598925693823\n",
      "0.865478515625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.64      0.34       224\n",
      "           1       0.98      0.88      0.93      3872\n",
      "\n",
      "    accuracy                           0.87      4096\n",
      "   macro avg       0.61      0.76      0.63      4096\n",
      "weighted avg       0.94      0.87      0.89      4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balanced_bagging = BalancedBaggingClassifier(base_estimator=model_bagging,\n",
    "...                                 sampling_strategy='auto',n_estimators=20,\n",
    "...                                 replacement=True,\n",
    "...                                 random_state=42)\n",
    "model_bagged = balanced_bagging.fit(X_train, y_train)\n",
    "results(model_bagged,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.05892406608610727\n",
      "0.0546875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      1.00      0.10       224\n",
      "           1       0.00      0.00      0.00      3872\n",
      "\n",
      "    accuracy                           0.05      4096\n",
      "   macro avg       0.03      0.50      0.05      4096\n",
      "weighted avg       0.00      0.05      0.01      4096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\dslab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_adaboost = AdaBoostClassifier(base_estimator = model_bagging)\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "results(model_adaboost,X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
